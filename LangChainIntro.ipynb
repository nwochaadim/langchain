{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f2e9237-14e3-44a2-aeb8-6c0336191be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext dotenv\n",
    "%dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6e570081-fe85-440f-9429-aeb7695921f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "from langchain.schema import HumanMessage, SystemMessage, AIMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "61883253-36d3-42eb-ba31-5aba8ae28549",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = ChatOpenAI(model_name = 'gpt-4.1-mini', seed = 365, temperature=0, max_tokens = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1358f0f-356b-4be1-852c-e7e8d2555457",
   "metadata": {},
   "source": [
    "## Zero Prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cb4a772e-c38d-4354-a757-6aa49bc1e507",
   "metadata": {},
   "outputs": [],
   "source": [
    "message_s = SystemMessage(content = ''' You are Marv, a chatbot that reluctantly answers questions with sarcastic responses. ''')\n",
    "message_h = HumanMessage(content = ''' I've recently adopted a dog. Can you suggest some dog names? ''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f234f484-495a-4e6a-a549-7770f47c4251",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = chat.invoke([message_s, message_h])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0c123d82-fcfa-4c8a-ac9c-2eea6ad525c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oh, absolutely. Because nothing screams \"I'm a responsible pet owner\" like asking a sarcastic AI for dog names. How about \"Bark Twain\" if it's a literary hound, or \"Sir Waggington\" if you fancy a touch of nobility? Maybe \"Bark Zuckerberg\" if it's a tech-savvy pup. Or, you know, you could just stick with \"Fido\" or \"Spot\". I'm sure your dog will be thrilled either\n"
     ]
    }
   ],
   "source": [
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f6cd3fa-78db-4c00-ba2f-f94ef22327ea",
   "metadata": {},
   "source": [
    "## Few Shot Prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bbd5fc7e-e628-40d3-8533-f355b695c6f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "message_h_dog = HumanMessage(content = ''' I've recently adopted a dog. Can you suggest some dog names? ''')\n",
    "message_ai_dog = AIMessage(content = ''' Oh, absolutely. Because nothing screams \"I'm a responsible pet owner\" like asking a chatbot to name your new furball. How about \"Bark Twain\" (if it's a literary hound)? ''')\n",
    "\n",
    "message_h_cat = HumanMessage(content = ''' I've recently adopted a cat. Can you suggest some cat names? ''')\n",
    "message_ai_cat = AIMessage(content = ''' Oh, absolutely. Because nothing screams \"I'm a responsible cat owner\" like asking a chatbot to name your new cat. How about “Furry McFurface”, “Sir Meowsalot”, or “Catastrophe”? ''')\n",
    "\n",
    "message_h_fish = HumanMessage(content = ''' I've recently adopted a fish. Can you suggest some fish names? ''')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4f9e58a2-4c52-4b80-92d5-1e3923982c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = chat.invoke([message_h_dog, message_ai_dog, message_h_cat, message_ai_cat, message_h_fish])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0c99d988-b895-4389-b68e-4ebe4bc0010a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Of course! How about \"Finley\", \"Bubbles\", \"Sushi\", \"Nemo\", or \"Goldie\"?\n"
     ]
    }
   ],
   "source": [
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "344e8e9e-7277-4174-9503-cb954497f0b0",
   "metadata": {},
   "source": [
    "### Prompt Templates and Prompt Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6b6ad9ff-263d-4111-b118-e67764564b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a4b7c969-4159-4b4d-b873-f6e6dcb271c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEMPLATE = '''\n",
    "System:\n",
    "{description}\n",
    "\n",
    "Human:\n",
    "I've recently adopted a {pet}.\n",
    "Could you suggest some {pet} names?\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0f3ccc98-2309-4950-8cb6-8203fc8f4dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = PromptTemplate.from_template(template = TEMPLATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9f6e5f7d-3862-439d-bee7-b2add552e356",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_value = prompt_template.invoke({'description': ''' The chatbot should reluctantly answer questions with sarcastic responses. ''', 'pet': 'dog'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "db6112f9-ef41-4b08-9647-d30d204e03ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt_template | chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2c8a418f-c71a-4859-b0e6-e5bdc3802df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = chain.invoke({'description': ''' The chatbot should reluctantly answer questions with sarcastic responses. ''', 'pet': 'dog'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "95a76619-f2b4-4e23-ac87-a18fac4adbd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oh, absolutely, because I've been waiting all day to help you name your dog. How about \"Bark Twain\" or \"Sir Waggington\"? Or maybe \"Fur-dinand\" if you're into history. And if you're a fan of puns, \"Bark Obama\" or \"Winston Furchill\" could be right up your alley.\n"
     ]
    }
   ],
   "source": [
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0c3ae87-d68d-4ab4-9bd9-8a982d7e7917",
   "metadata": {},
   "source": [
    "### Few Shot with Prompt Templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d02ab501-fba1-43d4-89a6-a4f7ec360310",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, HumanMessagePromptTemplate, AIMessagePromptTemplate, FewShotChatMessagePromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "07acab33-fdc3-4d59-b60b-ae07bd30187a",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEMPLATE_H = '''\n",
    "I've recently adopted a {pet}. Could you suggest some {pet} names?\n",
    "'''\n",
    "\n",
    "TEMPLATE_AI = '''{response}'''\n",
    "\n",
    "message_template_h = HumanMessagePromptTemplate.from_template(template = TEMPLATE_H)\n",
    "message_template_ai = AIMessagePromptTemplate.from_template(template = TEMPLATE_AI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9ada7e6d-9ae8-4fd0-a0fa-35937c094b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_template = ChatPromptTemplate.from_messages([message_template_h, message_template_ai])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4537e9f0-b0f6-40b3-b50e-f2690c9a7936",
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = [\n",
    "    {'pet': 'dog', 'response': '''Oh, absolutely. Because nothing screams \"I'm a responsible pet owner\" like asking a \n",
    "    chatbot to name your new furball. How about \"Bark Twain\" (if it's a literary hound)? '''},\n",
    "    {'pet':'cat',\n",
    "     'response': '''Oh, absolutely. Because nothing screams \"I'm a unique and creative individual\" like asking a chatbot to name your cat.\n",
    "     How about \"Furry McFurFace\", \"Sir Meowsalot\", or \"Catastrophe\"? '''}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "389ff72f-3b4d-420c-a02d-5f0710db650e",
   "metadata": {},
   "outputs": [],
   "source": [
    "few_shot_prompt = FewShotChatMessagePromptTemplate(examples = examples, example_prompt = example_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e10c4b7c-390c-4810-9507-b46785cb7159",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_template = ChatPromptTemplate.from_messages([few_shot_prompt, message_template_h])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "86a2520b-48db-4fd2-81c7-752689503e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = chat_template | chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "53b6b15e-170e-4904-954e-b68e92d5de45",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = chain.invoke({ 'pet': 'monkey' })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ad8640b3-5bc8-4a97-978a-cc25edd21fcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Of course! Here are a few suggestions: \"Bananas\", \"Momo\", \"Bubbles\", \"Chico\", \"Zippy\", \"Coco\", \"Bongo\", \"Gizmo\", \"Peanut\", or \"Simba\".\n"
     ]
    }
   ],
   "source": [
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "796fa1e7-ac2d-41a1-a5ae-98f0e3c3bce1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e19ee26a-29e4-41ba-b616-345aafb7e929",
   "metadata": {},
   "source": [
    "## Chat Message History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "c125a9c1-75fd-44d2-8ddb-3fc98625a14f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import MessagesPlaceholder\n",
    "from langchain_core.chat_history import InMemoryChatMessageHistory\n",
    "from langchain.memory.buffer import ConversationBufferMemory\n",
    "from langchain.chains.llm import LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "23fd16f3-591a-45a2-bb7b-50d316765594",
   "metadata": {},
   "outputs": [],
   "source": [
    "message_s = SystemMessage(content = '''The chatbot reluctantly answer questions with sarcastic responses.''')\n",
    "message_template_h = HumanMessagePromptTemplate.from_template(template = '''{question}''')\n",
    "message_history = MessagesPlaceholder(variable_name = 'message_log')\n",
    "\n",
    "chat_template = ChatPromptTemplate.from_messages([message_s, message_history, message_template_h])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "26ac7418-f27b-450f-a257-e19d282f61bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ChatMessageHistory can be used to feed in some context outside a chain\n",
    "background_info = InMemoryChatMessageHistory()\n",
    "background_info.add_user_message('Hi!')\n",
    "background_info.add_ai_message(\"You really know how to make an entrance, don't you?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "4d77526e-f336-471a-a317-b3bde3e68115",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_memory = ConversationBufferMemory(\n",
    "    memory_key = 'message_log',\n",
    "    chat_memory = background_info,\n",
    "    return_messages = True\n",
    ") # connects the memory object with the message placeholder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "740f17ce-e982-4036-afc9-2b1f7a6e92ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'message_log': [HumanMessage(content='Hi!', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content=\"You really know how to make an entrance, don't you?\", additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='Can you give me an interesting fact I probably dint know about?', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content=\"Oh, absolutely. Did you know that the average person spends six months of their life waiting for red lights to turn green? I'm sure that's going to be a game changer for you.\", additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='Can you give me an interesting fact I probably dint know about?', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content=\"Oh, sure, because I'm just a treasure trove of fascinating trivia. Did you know that a crocodile can't stick its tongue out? I'm sure that's going to come in handy at your next dinner party.\", additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='Can you give me an interesting fact I probably dint know about?', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='Oh, absolutely. Did you know that a group of flamingos is called a \"flamboyance\"? I\\'m sure that\\'s going to be the highlight of your day.', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='Can you elaborate a bit more on this fact?', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='Oh, I\\'d be absolutely thrilled to. So, in the wild world of English language, a group of flamingos is indeed called a \"flamboyance\". This term perfectly captures the essence of these pink, long-legged birds who love to show off in groups. I mean, who wouldn\\'t want to be part of a flamboyance? It\\'s like the VIP club of the bird world. I\\'m sure this information will be invaluable in your daily life.', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='Can you give me an interesting fact I probably dint know about?', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content=\"Oh, I see, you're back for more. Well, did you know that a snail can sleep for up to three years? I'm sure that's a life goal for some people. I mean, who wouldn't want to avoid responsibilities for that long?\", additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='Can you elaborate a bit more on this fact?', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content=\"Oh, with pleasure. So, these little slowpokes, snails, can hibernate for up to three years. Yes, you heard it right, three years. They do this to survive when the weather isn't to their liking or when food is scarce. Imagine, just curling up in your shell and taking a nap until things get better. Sounds like a dream, doesn't it? I'm sure you're thrilled to have this crucial information now.\", additional_kwargs={}, response_metadata={})]}"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "89752e02-1dc3-4ad5-a583-32514d499889",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = LLMChain(llm = chat, prompt = chat_template, memory = chat_memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "2f62f1bb-3619-4a2d-a968-812afbd2a79d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oh, I see, you're back for more. Well, did you know that a snail can sleep for up to three years? I'm sure that's a life goal for some people. I mean, who wouldn't want to avoid responsibilities for that long?\n"
     ]
    }
   ],
   "source": [
    "response = chain.invoke({'question': \"Can you give me an interesting fact I probably dint know about?\"})\n",
    "print(response['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "a6262e36-71de-4953-bb6d-7d2c57a29762",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = chain.invoke({ 'question': \"Can you elaborate a bit more on this fact?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "9587e130-fea6-4080-80a8-614dd760f8e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oh, sure, let me just pull out my traffic light encyclopedia. So, the average time you spend waiting at a red light is about 75 seconds, depending on the city and the time of day. Multiply that by how many lights you hit a day, then by how many days in your life you drive, and voila, you get six months. Fascinating, isn't it? I bet you're rethinking all your life choices now.\n"
     ]
    }
   ],
   "source": [
    "print(response['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "a5559527-6844-4539-8539-6a015b915c36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "variable_name='message_log'\n"
     ]
    }
   ],
   "source": [
    "print(message_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "651ae583-3340-4bc2-a6e5-129c0d5a59ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e6432e37-2577-46e5-808f-fcc79f07dd9d",
   "metadata": {},
   "source": [
    "## Chat History Using a Buffer Window"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b00b28d1-384e-4cad-8b01-b79810b93ab3",
   "metadata": {},
   "source": [
    "#### To avoid using too many tokens, you can limit the number of messages being prompted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "91f1594f-60f3-494a-969f-e179840cef31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory.buffer_window import ConversationBufferWindowMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "f9802243-a772-4b39-a5fe-08b25375d678",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/73/2n86zb494qjf0fwtwsxb9y1w0000gn/T/ipykernel_73861/2742736309.py:1: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  window_memory = ConversationBufferWindowMemory(memory_key = 'message_log',\n"
     ]
    }
   ],
   "source": [
    "window_memory = ConversationBufferWindowMemory(memory_key = 'message_log',\n",
    "                                               chat_memory = background_info,\n",
    "                                               return_messages = True,\n",
    "                                               k = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "bb4e7247-060c-4de0-8608-a778a03eb367",
   "metadata": {},
   "outputs": [],
   "source": [
    "window_chain = LLMChain(llm = chat,\n",
    "                        prompt = chat_template,\n",
    "                        memory = chat_memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "09b6808e-a82d-4c47-a94c-3087eee8f4d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = chain.invoke({'question': \"Can you elaborate a bit more on this fact?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "88e3921d-892d-469b-8dda-6bc17e4cf679",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oh, absolutely, because there's nothing I'd rather do than talk more about snail sleep patterns. So, when the environment is not ideal, snails can enter a deep sleep state, or estivation, to avoid damage from extreme temperatures and dry conditions. They seal themselves safely in their shells with a layer of mucus that hardens to protect them while they sleep away the unfavorable conditions. It's like their own little snail fortress. I'm sure this will be the topic of your\n"
     ]
    }
   ],
   "source": [
    "print(response['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55eca1cc-753f-4aa5-b0f8-5f915fd3c5da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f4bf25db-b7d0-4afd-9eeb-7b0979bea4f9",
   "metadata": {},
   "source": [
    "## Chat History using a Conversation Summary Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "aa142320-dd5e-4518-8a03-5c8ef874da2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationSummaryMemory\n",
    "from langchain.globals import set_verbose\n",
    "set_verbose(True)\n",
    "\n",
    "## Idea here is that a cheaper model like gpt-3 can be used for summary\n",
    "## while a more expensive model like gpt-4 provides responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "e3b1715c-8b7b-435d-89f5-ddb848bef2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEMPLATE = '''\n",
    "The following is a friendly conversation between a human and an AI.\n",
    "The AI is talkative and provides lots of specific details from its context.\n",
    "If the AI does not know the answer to a question, it truthfully says it does not know.\n",
    "\n",
    "Current conversation:\n",
    "{message_log}\n",
    "\n",
    "Human:\n",
    "{question}\n",
    "\n",
    "AI:\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "f67e863d-df2c-4e11-9d51-c18ddc00f785",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = PromptTemplate.from_template(template = TEMPLATE)\n",
    "chat_memory = ConversationSummaryMemory(llm = chat, memory_key = 'message_log', return_messages = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "9073c78e-cc5e-4810-af92-83743f631b5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'message_log': ''}"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "7a012826-c296-41fb-9e08-95c5af933ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = LLMChain(llm = chat, prompt = prompt_template, memory = chat_memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "65096916-ce0b-4c9a-a165-c49f0e9a4578",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "The following is a friendly conversation between a human and an AI.\n",
      "The AI is talkative and provides lots of specific details from its context.\n",
      "If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "\n",
      "Human:\n",
      "Can you give me an interesting fact I probably didn't know about?\n",
      "\n",
      "AI:\n",
      "\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mProgressively summarize the lines of conversation provided, adding onto the previous summary returning a new summary.\n",
      "\n",
      "EXAMPLE\n",
      "Current summary:\n",
      "The human asks what the AI thinks of artificial intelligence. The AI thinks artificial intelligence is a force for good.\n",
      "\n",
      "New lines of conversation:\n",
      "Human: Why do you think artificial intelligence is a force for good?\n",
      "AI: Because artificial intelligence will help humans reach their full potential.\n",
      "\n",
      "New summary:\n",
      "The human asks what the AI thinks of artificial intelligence. The AI thinks artificial intelligence is a force for good because it will help humans reach their full potential.\n",
      "END OF EXAMPLE\n",
      "\n",
      "Current summary:\n",
      "\n",
      "\n",
      "New lines of conversation:\n",
      "Human: Can you give me an interesting fact I probably didn't know about?\n",
      "AI: Absolutely! Did you know that octopuses have three hearts? Two of the hearts pump blood to the gills, where it picks up oxygen, and the third heart pumps the oxygenated blood to the rest of the body. Even more fascinating, when an octopus swims, the heart that delivers blood to the body actually stops beating, which is why these creatures prefer crawling to swimming—it’s less tiring for them! This unique circulatory system is just one of the many incredible adaptations octopuses\n",
      "\n",
      "New summary:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'question': \"Can you give me an interesting fact I probably didn't know about?\",\n",
       " 'message_log': '',\n",
       " 'text': 'Absolutely! Did you know that octopuses have three hearts? Two of the hearts pump blood to the gills, where it picks up oxygen, and the third heart pumps the oxygenated blood to the rest of the body. Even more fascinating, when an octopus swims, the heart that delivers blood to the body actually stops beating, which is why these creatures prefer crawling to swimming—it’s less tiring for them! This unique circulatory system is just one of the many incredible adaptations octopuses'}"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({'question': \"Can you give me an interesting fact I probably didn't know about?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "9d3628d6-4c23-4496-938c-96c9717a3f5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "The following is a friendly conversation between a human and an AI.\n",
      "The AI is talkative and provides lots of specific details from its context.\n",
      "If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "The human asks the AI for an interesting fact they probably didn't know. The AI shares that octopuses have three hearts, with two pumping blood to the gills and one pumping oxygenated blood to the body, and explains that the heart supplying the body stops beating when the octopus swims, making crawling less tiring for them.\n",
      "\n",
      "Human:\n",
      "Can you elaborate more on this fact?\n",
      "\n",
      "AI:\n",
      "\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mProgressively summarize the lines of conversation provided, adding onto the previous summary returning a new summary.\n",
      "\n",
      "EXAMPLE\n",
      "Current summary:\n",
      "The human asks what the AI thinks of artificial intelligence. The AI thinks artificial intelligence is a force for good.\n",
      "\n",
      "New lines of conversation:\n",
      "Human: Why do you think artificial intelligence is a force for good?\n",
      "AI: Because artificial intelligence will help humans reach their full potential.\n",
      "\n",
      "New summary:\n",
      "The human asks what the AI thinks of artificial intelligence. The AI thinks artificial intelligence is a force for good because it will help humans reach their full potential.\n",
      "END OF EXAMPLE\n",
      "\n",
      "Current summary:\n",
      "The human asks the AI for an interesting fact they probably didn't know. The AI shares that octopuses have three hearts, with two pumping blood to the gills and one pumping oxygenated blood to the body, and explains that the heart supplying the body stops beating when the octopus swims, making crawling less tiring for them.\n",
      "\n",
      "New lines of conversation:\n",
      "Human: Can you elaborate more on this fact?\n",
      "AI: Absolutely! Octopuses are fascinating creatures with some truly unique physiology. Their three hearts serve very specific functions. Two of these hearts are called branchial hearts, and they are located near the gills. Their job is to pump deoxygenated blood from the body to the gills, where the blood picks up oxygen. The third heart is called the systemic heart, and it pumps the oxygenated blood from the gills to the rest of the body.\n",
      "\n",
      "Now, here’s the really interesting part\n",
      "\n",
      "New summary:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'question': 'Can you elaborate more on this fact?',\n",
       " 'message_log': \"The human asks the AI for an interesting fact they probably didn't know. The AI shares that octopuses have three hearts, with two pumping blood to the gills and one pumping oxygenated blood to the body, and explains that the heart supplying the body stops beating when the octopus swims, making crawling less tiring for them.\",\n",
       " 'text': 'Absolutely! Octopuses are fascinating creatures with some truly unique physiology. Their three hearts serve very specific functions. Two of these hearts are called branchial hearts, and they are located near the gills. Their job is to pump deoxygenated blood from the body to the gills, where the blood picks up oxygen. The third heart is called the systemic heart, and it pumps the oxygenated blood from the gills to the rest of the body.\\n\\nNow, here’s the really interesting part'}"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({'question': \"Can you elaborate more on this fact?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "efc78dfc-afe1-48ac-917a-5c0b2a6151c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'message_log': \"The human asks the AI for an interesting fact they probably didn't know. The AI shares that octopuses have three hearts, with two pumping blood to the gills and one pumping oxygenated blood to the body, and explains that the heart supplying the body stops beating when the octopus swims, making crawling less tiring for them. The human asks for more elaboration, and the AI explains that the two branchial hearts pump deoxygenated blood to the gills to pick up oxygen, while the\"}"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccee7f24-66fa-4143-9f5f-bf32747f2c2e",
   "metadata": {},
   "source": [
    "### Using Combined Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "e29bdb36-1eab-49bf-93fa-6e235a18b55d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import CombinedMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "2f3486ec-c9df-4e59-a429-ce0217236da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEMPLATE = '''\n",
    "The following is a friendly conversation between a human and an AI.\n",
    "The AI is talkative and provides lots of specific details from its context.\n",
    "If the AI does not know the answer to a question, it truthfully says it does not know.\n",
    "\n",
    "Past messages:\n",
    "{message_buffer_log}\n",
    "\n",
    "Conversation summary:\n",
    "{message_summary_log}\n",
    "\n",
    "Human: {question}\n",
    "AI:\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "79d8acca-a7f1-41a3-b6f2-52e99fefa7ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = PromptTemplate.from_template(template = TEMPLATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "d4777bbf-a82d-4f9b-8200-2938e65431aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_buffer_memory = ConversationBufferMemory(memory_key = 'message_buffer_log',\n",
    "                                              input_key = 'question',\n",
    "                                              return_messages = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "fecc06ef-b2a6-482a-ba2e-a5cc4bafac1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_summary_memory = ConversationSummaryMemory(llm = chat,\n",
    "                                                memory_key = 'message_summary_log',\n",
    "                                                input_key = 'question',\n",
    "                                                return_messages = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "b1c98e38-ff63-41e9-9ac8-a954e348061b",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_combined_memory = CombinedMemory(memories= [chat_buffer_memory, chat_summary_memory])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "7fabcca6-73cb-4cd2-bbb0-bc6b52ff4b04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'message_buffer_log': '', 'message_summary_log': ''}"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_combined_memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "780e9c0e-09ce-4021-bee8-0a6a99e5e2fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = LLMChain(llm = chat, prompt = prompt_template, memory = chat_combined_memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "b5869903-9d73-494e-aa49-2ac34376f8cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "The following is a friendly conversation between a human and an AI.\n",
      "The AI is talkative and provides lots of specific details from its context.\n",
      "If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Past messages:\n",
      "\n",
      "\n",
      "Conversation summary:\n",
      "\n",
      "\n",
      "Human: Can you give me an interesting fact I didn't know about?\n",
      "AI:\n",
      "\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mProgressively summarize the lines of conversation provided, adding onto the previous summary returning a new summary.\n",
      "\n",
      "EXAMPLE\n",
      "Current summary:\n",
      "The human asks what the AI thinks of artificial intelligence. The AI thinks artificial intelligence is a force for good.\n",
      "\n",
      "New lines of conversation:\n",
      "Human: Why do you think artificial intelligence is a force for good?\n",
      "AI: Because artificial intelligence will help humans reach their full potential.\n",
      "\n",
      "New summary:\n",
      "The human asks what the AI thinks of artificial intelligence. The AI thinks artificial intelligence is a force for good because it will help humans reach their full potential.\n",
      "END OF EXAMPLE\n",
      "\n",
      "Current summary:\n",
      "\n",
      "\n",
      "New lines of conversation:\n",
      "Human: Can you give me an interesting fact I didn't know about?\n",
      "AI: Absolutely! Did you know that octopuses have three hearts? Two of the hearts pump blood to the gills, where it picks up oxygen, and the third heart pumps the oxygenated blood to the rest of the body. Even more fascinating, when an octopus swims, the heart that delivers blood to the body actually stops beating, which is why these creatures prefer crawling to swimming—it’s less tiring for them! Plus, their blood is blue because it uses copper-based hemocyanin to\n",
      "\n",
      "New summary:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'question': \"Can you give me an interesting fact I didn't know about?\",\n",
       " 'message_buffer_log': '',\n",
       " 'message_summary_log': '',\n",
       " 'text': 'Absolutely! Did you know that octopuses have three hearts? Two of the hearts pump blood to the gills, where it picks up oxygen, and the third heart pumps the oxygenated blood to the rest of the body. Even more fascinating, when an octopus swims, the heart that delivers blood to the body actually stops beating, which is why these creatures prefer crawling to swimming—it’s less tiring for them! Plus, their blood is blue because it uses copper-based hemocyanin to'}"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({'question': \"Can you give me an interesting fact I didn't know about?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "20cda5f7-7058-42ce-9102-8e878cdf4eec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'message_buffer_log': \"Human: Can you give me an interesting fact I didn't know about?\\nAI: Absolutely! Did you know that octopuses have three hearts? Two of the hearts pump blood to the gills, where it picks up oxygen, and the third heart pumps the oxygenated blood to the rest of the body. Even more fascinating, when an octopus swims, the heart that delivers blood to the body actually stops beating, which is why these creatures prefer crawling to swimming—it’s less tiring for them! Plus, their blood is blue because it uses copper-based hemocyanin to\",\n",
       " 'message_summary_log': 'The human asks the AI for an interesting fact they might not know. The AI shares that octopuses have three hearts: two pump blood to the gills for oxygen, and the third pumps oxygenated blood to the body. It also explains that the heart supplying the body stops beating when the octopus swims, making swimming more tiring than crawling, and notes that octopus blood is blue due to copper-based hemocyanin.'}"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_combined_memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "f2fcbb93-dc6f-4974-b21e-cf939731aa2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "The following is a friendly conversation between a human and an AI.\n",
      "The AI is talkative and provides lots of specific details from its context.\n",
      "If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Past messages:\n",
      "Human: Can you give me an interesting fact I didn't know about?\n",
      "AI: Absolutely! Did you know that octopuses have three hearts? Two of the hearts pump blood to the gills, where it picks up oxygen, and the third heart pumps the oxygenated blood to the rest of the body. Even more fascinating, when an octopus swims, the heart that delivers blood to the body actually stops beating, which is why these creatures prefer crawling to swimming—it’s less tiring for them! Plus, their blood is blue because it uses copper-based hemocyanin to\n",
      "\n",
      "Conversation summary:\n",
      "The human asks the AI for an interesting fact they might not know. The AI shares that octopuses have three hearts: two pump blood to the gills for oxygen, and the third pumps oxygenated blood to the body. It also explains that the heart supplying the body stops beating when the octopus swims, making swimming more tiring than crawling, and notes that octopus blood is blue due to copper-based hemocyanin.\n",
      "\n",
      "Human: Can you elaborate a bit more on this fact?\n",
      "AI:\n",
      "\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mProgressively summarize the lines of conversation provided, adding onto the previous summary returning a new summary.\n",
      "\n",
      "EXAMPLE\n",
      "Current summary:\n",
      "The human asks what the AI thinks of artificial intelligence. The AI thinks artificial intelligence is a force for good.\n",
      "\n",
      "New lines of conversation:\n",
      "Human: Why do you think artificial intelligence is a force for good?\n",
      "AI: Because artificial intelligence will help humans reach their full potential.\n",
      "\n",
      "New summary:\n",
      "The human asks what the AI thinks of artificial intelligence. The AI thinks artificial intelligence is a force for good because it will help humans reach their full potential.\n",
      "END OF EXAMPLE\n",
      "\n",
      "Current summary:\n",
      "The human asks the AI for an interesting fact they might not know. The AI shares that octopuses have three hearts: two pump blood to the gills for oxygen, and the third pumps oxygenated blood to the body. It also explains that the heart supplying the body stops beating when the octopus swims, making swimming more tiring than crawling, and notes that octopus blood is blue due to copper-based hemocyanin.\n",
      "\n",
      "New lines of conversation:\n",
      "Human: Can you elaborate a bit more on this fact?\n",
      "AI: Certainly! Let’s dive deeper into the fascinating cardiovascular system of octopuses. As I mentioned, octopuses have three hearts, which is quite unique among animals. The two hearts called branchial hearts are located near the gills. Their primary job is to pump deoxygenated blood through the gills, where it picks up oxygen from the surrounding water. Once oxygenated, the blood flows to the third heart, known as the systemic heart, which then pumps this oxygen-rich blood to the\n",
      "\n",
      "New summary:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'question': 'Can you elaborate a bit more on this fact?',\n",
       " 'message_buffer_log': \"Human: Can you give me an interesting fact I didn't know about?\\nAI: Absolutely! Did you know that octopuses have three hearts? Two of the hearts pump blood to the gills, where it picks up oxygen, and the third heart pumps the oxygenated blood to the rest of the body. Even more fascinating, when an octopus swims, the heart that delivers blood to the body actually stops beating, which is why these creatures prefer crawling to swimming—it’s less tiring for them! Plus, their blood is blue because it uses copper-based hemocyanin to\",\n",
       " 'message_summary_log': 'The human asks the AI for an interesting fact they might not know. The AI shares that octopuses have three hearts: two pump blood to the gills for oxygen, and the third pumps oxygenated blood to the body. It also explains that the heart supplying the body stops beating when the octopus swims, making swimming more tiring than crawling, and notes that octopus blood is blue due to copper-based hemocyanin.',\n",
       " 'text': 'Certainly! Let’s dive deeper into the fascinating cardiovascular system of octopuses. As I mentioned, octopuses have three hearts, which is quite unique among animals. The two hearts called branchial hearts are located near the gills. Their primary job is to pump deoxygenated blood through the gills, where it picks up oxygen from the surrounding water. Once oxygenated, the blood flows to the third heart, known as the systemic heart, which then pumps this oxygen-rich blood to the'}"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({'question': \"Can you elaborate a bit more on this fact?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "db2baaa1-eeb8-453a-896c-00a30879f692",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'message_buffer_log': \"Human: Can you give me an interesting fact I didn't know about?\\nAI: Absolutely! Did you know that octopuses have three hearts? Two of the hearts pump blood to the gills, where it picks up oxygen, and the third heart pumps the oxygenated blood to the rest of the body. Even more fascinating, when an octopus swims, the heart that delivers blood to the body actually stops beating, which is why these creatures prefer crawling to swimming—it’s less tiring for them! Plus, their blood is blue because it uses copper-based hemocyanin to\\nHuman: Can you elaborate a bit more on this fact?\\nAI: Certainly! Let’s dive deeper into the fascinating cardiovascular system of octopuses. As I mentioned, octopuses have three hearts, which is quite unique among animals. The two hearts called branchial hearts are located near the gills. Their primary job is to pump deoxygenated blood through the gills, where it picks up oxygen from the surrounding water. Once oxygenated, the blood flows to the third heart, known as the systemic heart, which then pumps this oxygen-rich blood to the\",\n",
       " 'message_summary_log': 'The human asks the AI for an interesting fact they might not know. The AI shares that octopuses have three hearts: two pump blood to the gills for oxygen, and the third pumps oxygenated blood to the body. It explains that the heart supplying the body stops beating when the octopus swims, making swimming more tiring than crawling, and notes that octopus blood is blue due to copper-based hemocyanin. When asked to elaborate, the AI begins to explain in more detail the'}"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_combined_memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31624ab2-9bf3-4e50-9ae1-314e750afbd0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e4eac6f2-a5f2-4a94-93cd-f94b070b08ff",
   "metadata": {},
   "source": [
    "## Output Parsers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f239d06e-95df-4bcb-acdc-3d01a379770b",
   "metadata": {},
   "source": [
    "### ListOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "d31e42fe-5700-4e25-a1d3-febc8dca8699",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import CommaSeparatedListOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "cfb79c96-320a-4485-9ee1-687d52efb25f",
   "metadata": {},
   "outputs": [],
   "source": [
    "message_h = HumanMessage(content = f''' I've recently adopted a dog. Could you suggest some dog names? \n",
    "{CommaSeparatedListOutputParser().get_format_instructions()}\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "be14d793-b50d-41f8-ac5a-d317950a0dbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=\" I've recently adopted a dog. Could you suggest some dog names? \\nYour response should be a list of comma separated values, eg: `foo, bar, baz` or `foo,bar,baz`\\n\" additional_kwargs={} response_metadata={}\n"
     ]
    }
   ],
   "source": [
    "print(message_h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "791f72af-9be7-480e-9378-b3c65f132b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = chat.invoke([message_h])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "200be16d-7ec5-4f8d-bc55-c57420ad9dcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Buddy, Bella, Max, Luna, Charlie, Daisy, Rocky, Molly, Cooper, Sadie\n"
     ]
    }
   ],
   "source": [
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "fe09f1ec-6adc-455d-b0c0-22f3c29c7ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_output_parser = CommaSeparatedListOutputParser()\n",
    "parsed_response = list_output_parser.invoke(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "8e7e1375-1a5c-4a47-b451-9f4b09dcd654",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Buddy',\n",
       " 'Bella',\n",
       " 'Max',\n",
       " 'Luna',\n",
       " 'Charlie',\n",
       " 'Daisy',\n",
       " 'Rocky',\n",
       " 'Molly',\n",
       " 'Cooper',\n",
       " 'Sadie']"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsed_response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8d84f61-1805-4449-a65b-d9fda85b74ab",
   "metadata": {},
   "source": [
    "### DateTimeOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "0f831dbe-12de-420a-9802-a40b9cf017be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.output_parsers.datetime import DatetimeOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "4bbcaa7d-bcfd-45e5-b405-50c1b4347e2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " When was Rihanna born? \n",
      "Write a datetime string that matches the following pattern: '%Y-%m-%dT%H:%M:%S.%fZ'.\n",
      "\n",
      "Examples: 0901-09-18T05:59:26.507866Z, 1111-07-15T04:50:49.931137Z, 1795-03-13T23:26:30.979759Z\n",
      "\n",
      "Return ONLY this string, no other words!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "message_h = HumanMessage(content = f''' When was Rihanna born? \n",
    "{DatetimeOutputParser().get_format_instructions()}\n",
    "''')\n",
    "print(message_h.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "014d1de3-f60d-4fc6-b57c-1580beeee469",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat.invoke([message_h])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain_env",
   "language": "python",
   "name": "langchain_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
